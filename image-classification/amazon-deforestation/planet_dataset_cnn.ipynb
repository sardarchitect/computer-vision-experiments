{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "emotional-rochester",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "minimal-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-discovery",
   "metadata": {},
   "source": [
    "## DATAROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "flying-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = './data/planet/'\n",
    "train_root = os.path.join(dataroot,'train-jpg/')\n",
    "test_root = os.path.join(dataroot,'test-jpg/')\n",
    "train_label_root = os.path.join(dataroot,'train_classes.csv')\n",
    "test_label_root = os.path.join(dataroot,'test_classes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-cedar",
   "metadata": {},
   "source": [
    "## HYPERPARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "occupational-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 256\n",
    "num_workers = 4\n",
    "pin_memory = True\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(32),    \n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "lr = 0.01\n",
    "momentum = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "loose-study",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40479"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(train_label_root)\n",
    "len(df[\"image_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "crude-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(train_root+df[\"image_name\"][0]+\".jpg\")\n",
    "# img = img.convert('RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-consensus",
   "metadata": {},
   "source": [
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "italian-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dir, lbl_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        temp_df = pd.read_csv(lbl_dir)\n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        self.X_train = temp_df['image_name']\n",
    "        self.y_train = self.mlb.fit_transform(temp_df['tags'].str.split()).astype(np.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.X_train)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(train_root+df[\"image_name\"][index]+\".jpg\")\n",
    "        img = img.convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        label = torch.from_numpy(self.y_train[index])\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sapphire-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PlanetDataset(train_root, train_label_root, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "operating-extreme",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40479"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-bruce",
   "metadata": {},
   "source": [
    "## DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "skilled-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "inclusive-outreach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 32, 32]) torch.Size([256, 17])\n"
     ]
    }
   ],
   "source": [
    "for Xb, yb in train_dl:\n",
    "    print(Xb.shape, yb.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-xerox",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "registered-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "present-entry",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(2304, 256)\n",
    "        self.fc2 = nn.Linear(256, 17)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(x.size(0), -1) # Flatten layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.sigmoid(x)\n",
    "\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-wilson",
   "metadata": {},
   "source": [
    "## OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "invisible-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr, momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-latitude",
   "metadata": {},
   "source": [
    "## LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "atmospheric-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-machinery",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "gothic-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (Xb, yb) in enumerate(train_dl):\n",
    "        Xb = Xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(Xb)\n",
    "        loss = criterion(out, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(Xb), len(train_dl.dataset),\n",
    "                100. * batch_idx / len(train_dl), loss.data.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "tamil-converter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/40479 (0%)]\tLoss: 0.698192\n",
      "Train Epoch: 1 [2560/40479 (6%)]\tLoss: 0.691304\n",
      "Train Epoch: 1 [5120/40479 (13%)]\tLoss: 0.682352\n",
      "Train Epoch: 1 [7680/40479 (19%)]\tLoss: 0.672952\n",
      "Train Epoch: 1 [10240/40479 (25%)]\tLoss: 0.662355\n",
      "Train Epoch: 1 [12800/40479 (31%)]\tLoss: 0.648452\n",
      "Train Epoch: 1 [15360/40479 (38%)]\tLoss: 0.630642\n",
      "Train Epoch: 1 [17920/40479 (44%)]\tLoss: 0.602465\n",
      "Train Epoch: 1 [20480/40479 (50%)]\tLoss: 0.561632\n",
      "Train Epoch: 1 [23040/40479 (57%)]\tLoss: 0.517396\n",
      "Train Epoch: 1 [25600/40479 (63%)]\tLoss: 0.469789\n",
      "Train Epoch: 1 [28160/40479 (69%)]\tLoss: 0.422600\n",
      "Train Epoch: 1 [30720/40479 (75%)]\tLoss: 0.379018\n",
      "Train Epoch: 1 [33280/40479 (82%)]\tLoss: 0.360094\n",
      "Train Epoch: 1 [35840/40479 (88%)]\tLoss: 0.357801\n",
      "Train Epoch: 1 [38400/40479 (94%)]\tLoss: 0.342202\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 2):\n",
    "    train(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
