{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "label_dim = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.fcn = torch.nn.Sequential(\n",
    "            # Fully Connected Layer 1\n",
    "            torch.nn.Linear(\n",
    "                in_features=noise_dim + label_dim,\n",
    "                out_features=240,\n",
    "                bias=True\n",
    "            ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            # Fully Connected Layer 2\n",
    "            torch.nn.Linear(\n",
    "                in_features=240,\n",
    "                out_features=240,\n",
    "                bias=True\n",
    "            ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            # Fully Connected Layer 3\n",
    "            torch.nn.Linear(\n",
    "                in_features=240,\n",
    "                out_features=240,\n",
    "                bias=True\n",
    "            ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            # Fully Connected Layer 4\n",
    "            torch.nn.Linear(\n",
    "                in_features=240,\n",
    "                out_features=240,\n",
    "                bias=True\n",
    "            ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            # Fully Connected Layer 5\n",
    "            torch.nn.Linear(\n",
    "                in_features=240,\n",
    "                out_features=240,\n",
    "                bias=True\n",
    "            ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            # Fully Connected Layer 6\n",
    "            torch.nn.Linear(\n",
    "                in_features=240,\n",
    "                out_features=784,\n",
    "                bias=True\n",
    "            ),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, batch, labels):\n",
    "        inputs = batch.view(batch.size(0), -1)\n",
    "        ret = torch.cat((inputs, labels), dim=1)\n",
    "        ret = self.fcn(ret)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maxout Activation\n",
    "\n",
    "##### Source: https://github.com/pytorch/pytorch/issues/805"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Maxout(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_pieces):\n",
    "\n",
    "        super(Maxout, self).__init__()\n",
    "\n",
    "        self.num_pieces = num_pieces\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x.shape = (batch_size? x 625)\n",
    "\n",
    "        assert x.shape[1] % self.num_pieces == 0  # 625 % 5 = 0\n",
    "\n",
    "        ret = x.view(\n",
    "            *x.shape[:1],  # batch_size\n",
    "            x.shape[1] // self.num_pieces,  # piece-wise linear\n",
    "            self.num_pieces,  # num_pieces\n",
    "            *x.shape[2:]  # remaining dimensions if any\n",
    "        )\n",
    "        \n",
    "        # ret.shape = (batch_size? x 125 x 5)\n",
    "\n",
    "        # https://pytorch.org/docs/stable/torch.html#torch.max        \n",
    "        ret, _ = ret.max(dim=2)\n",
    "\n",
    "        # ret.shape = (batch_size? x 125)\n",
    "\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.fcn = torch.nn.Sequential(\n",
    "            # Fully Connected Layer 1\n",
    "            torch.nn.Linear(\n",
    "                in_features=784 + label_dim,\n",
    "                out_features=240,\n",
    "                bias=True\n",
    "            ),\n",
    "            Maxout(5),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            # Fully Connected Layer 2\n",
    "            torch.nn.Linear(\n",
    "                in_features=48,\n",
    "                out_features=240,\n",
    "                bias=True\n",
    "            ),\n",
    "            Maxout(5),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            # Fully Connected Layer 3\n",
    "            torch.nn.Linear(\n",
    "                in_features=48,\n",
    "                out_features=240,\n",
    "                bias=True\n",
    "            ),\n",
    "            Maxout(5),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            # Fully Connected Layer 4\n",
    "            torch.nn.Linear(\n",
    "                in_features=48,\n",
    "                out_features=1,\n",
    "                bias=True\n",
    "            ),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, batch, labels):\n",
    "        ret = batch.view(batch.size(0), -1)\n",
    "        ret = torch.cat((ret, labels), dim=1)\n",
    "        ret = self.fcn(ret)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenTransform:\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        return inputs.view(inputs.shape[0], -1)\n",
    "        \n",
    "\n",
    "data_train = torchvision.datasets.MNIST(\n",
    "    './data/mnist',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        FlattenTransform()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    data_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "discriminator_optimizer = torch.optim.SGD(\n",
    "    discriminator.parameters(),\n",
    "    lr=0.001,\n",
    "    momentum=0.5,\n",
    "#     dampening=0.0001\n",
    ")\n",
    "\n",
    "generator_optimizer = torch.optim.SGD(\n",
    "    generator.parameters(),\n",
    "    lr=0.001,\n",
    "    momentum=0.5,\n",
    "#     dampening=0.0001\n",
    ")\n",
    "\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "discriminator_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer=discriminator_optimizer,\n",
    "    step_size=1,\n",
    "    gamma=0.99,\n",
    "    last_epoch=-1\n",
    ")\n",
    "\n",
    "generator_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer=generator_optimizer,\n",
    "    step_size=1,\n",
    "    gamma=0.99,\n",
    "    last_epoch=-1\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lambda Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class DecayLR:\n",
    "    \n",
    "    def __init__(self, _lr, _step_size):\n",
    "        \n",
    "        self.lr = _lr\n",
    "        self.step_size = _step_size\n",
    "    \n",
    "    def __call__(self, _epoch):\n",
    "\n",
    "        if _epoch % self.step_size == 0:\n",
    "            self.lr = self.lr * 0.1\n",
    "        \n",
    "        return self.lr\n",
    "\n",
    "\n",
    "discriminator_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    discriminator_optimizer,\n",
    "    DecayLR(\n",
    "        _lr=0.9,\n",
    "        _step_size=100\n",
    "    )\n",
    ")\n",
    "\n",
    "generator_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    generator_optimizer,\n",
    "    DecayLR(\n",
    "        _lr=0.9,\n",
    "        _step_size=100\n",
    "    )\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeGAN(tgt_pth, images, labels, epoch):\n",
    "\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(20, 18))\n",
    "    \n",
    "    fig.suptitle('Epoch {}'.format(str(epoch).zfill(4)))\n",
    "\n",
    "    for row, axe in enumerate(axes):\n",
    "        for col, cell in enumerate(axe):\n",
    "            cell.imshow(\n",
    "                images[row * 5 + col],\n",
    "                cmap='gray'\n",
    "            )\n",
    "            \n",
    "            cell.set_title('{}'.format(\n",
    "                torch.argmax(labels[row * 5 + col])\n",
    "            ))\n",
    "\n",
    "            cell.axis(\"off\")\n",
    "\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig.savefig(os.path.join(tgt_pth, '{}.jpg'.format(str(epoch).zfill(3))))\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Onehot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeOneHot(labels):\n",
    "    ret = torch.FloatTensor(labels.shape[0], label_dim)\n",
    "    ret.zero_()\n",
    "    ret.scatter_(dim=1, index=labels.view(-1, 1), value=1)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_labels = torch.ones(BATCH_SIZE, 1).to(device)\n",
    "fake_labels = torch.zeros(BATCH_SIZE, 1).to(device)\n",
    "\n",
    "test_z = (2 * torch.randn(10, noise_dim) - 1).to(device)\n",
    "test_y = encodeOneHot(torch.tensor(np.arange(0, 10))).to(device)\n",
    "\n",
    "num_epochs = 256\n",
    "num_steps = len(train_loader) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "visuals_dir = 'visuals-section-3-lecture-2-c'\n",
    "\n",
    "if not os.path.exists(visuals_dir):\n",
    "    os.mkdir(visuals_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_loss_ls = []\n",
    "g_loss_ls = []\n",
    "d_lr_ls = []\n",
    "g_lr_ls = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Loss Log\n",
    "    d_counter = 0\n",
    "    g_counter = 0\n",
    "    d_loss = 0\n",
    "    g_loss = 0\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        if i == num_steps:\n",
    "            break\n",
    "\n",
    "        # Train Discriminator\n",
    "        for _ in range(4):\n",
    "        \n",
    "            real_images = images.to(device)\n",
    "            real_conditions = encodeOneHot(labels).to(device)\n",
    "            \n",
    "            fake_conditions = encodeOneHot(\n",
    "                torch.randint(0, 10, (BATCH_SIZE,))\n",
    "            ).to(device)\n",
    "\n",
    "            fake_images = generator(\n",
    "                (2 * torch.randn(BATCH_SIZE, noise_dim) - 1)\n",
    "                .to(device),\n",
    "                fake_conditions\n",
    "            )\n",
    "\n",
    "            discriminator_optimizer.zero_grad()\n",
    "            \n",
    "            real_outputs = discriminator(\n",
    "                real_images, real_conditions)\n",
    "            fake_outputs = discriminator(\n",
    "                fake_images, fake_conditions)\n",
    "            \n",
    "            d_x = criterion(real_outputs, real_labels)\n",
    "            d_g_z = criterion(fake_outputs, fake_labels)\n",
    "\n",
    "            d_x.backward()\n",
    "            d_g_z.backward()\n",
    "\n",
    "            discriminator_optimizer.step()\n",
    "            \n",
    "            # Loss Log\n",
    "            d_counter += 1\n",
    "            d_loss = d_x.item() + d_g_z.item()\n",
    "\n",
    "\n",
    "        # Train Generator\n",
    "        z = (2 * torch.randn(BATCH_SIZE, noise_dim) - 1).to(device)\n",
    "        y = encodeOneHot(torch.randint(0, 10, (BATCH_SIZE,))).to(device)\n",
    "\n",
    "        generator.zero_grad()\n",
    "\n",
    "        outputs = discriminator(generator(z, y), y)\n",
    "\n",
    "        loss = criterion(outputs, real_labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        generator_optimizer.step()\n",
    "        \n",
    "        # LR Decay\n",
    "#         discriminator_scheduler.step()\n",
    "#         generator_scheduler.step()\n",
    "        \n",
    "        # Loss Log\n",
    "        g_counter += 1\n",
    "        g_loss += loss.item()\n",
    "\n",
    "    # Loss Log\n",
    "    if epoch % 10 == 0:\n",
    "        print(\n",
    "            'e:{}, G:{:.3f}, D:{:.3f}'.format(\n",
    "                epoch,\n",
    "                g_loss / g_counter,\n",
    "                d_loss / d_counter\n",
    "#                 generator_scheduler.get_lr(),\n",
    "#                 discriminator_scheduler.get_lr()\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Loss Log for Plot\n",
    "    g_loss_ls.append(g_loss / g_counter)\n",
    "    d_loss_ls.append(d_loss / d_counter)\n",
    "    \n",
    "    # Learning Rate Decay Log\n",
    "#     g_lr_ls.append(generator_scheduler.get_lr())\n",
    "#     d_lr_ls.append(discriminator_scheduler.get_lr())\n",
    "\n",
    "\n",
    "    # Visualize Results\n",
    "    if epoch % 5 == 0:\n",
    "\n",
    "        generated = generator(test_z, test_y).detach().cpu().view(-1, 28, 28)\n",
    "\n",
    "        visualizeGAN(visuals_dir, generated, test_y, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Results\n",
    "generated = generator(test_z, test_y)\n",
    "                .detach().cpu().view(-1, 28, 28)\n",
    "\n",
    "visualizeGAN(visuals_dir, generated, test_y, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 10))\n",
    "plt.plot(d_loss_ls, label='D Loss')\n",
    "plt.plot(g_loss_ls, label='G Loss')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Learning Rate Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 10))\n",
    "plt.plot(d_lr_ls, label='D LR')\n",
    "plt.plot(g_lr_ls, label='G LR')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Results\n",
    "test_z = (2 * torch.randn(10, noise_dim) - 1).to(device)\n",
    "\n",
    "generated = generator(test_z, test_y).detach().cpu().view(-1, 1, 28, 28)\n",
    "\n",
    "grid = torchvision.utils.make_grid(\n",
    "    generated,\n",
    "    nrow=5,\n",
    "    padding=10,\n",
    "    pad_value=1\n",
    ")\n",
    "\n",
    "img = np.transpose(\n",
    "    grid.numpy(),\n",
    "    (1, 2, 0)\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google Collaboratory\n",
    "\n",
    "Notebook: https://colab.research.google.com/drive/1O0Id95mJUZLsxu3AJy8xCNMm5phbeYh7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
